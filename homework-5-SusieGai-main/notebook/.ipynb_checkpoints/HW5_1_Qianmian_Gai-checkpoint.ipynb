{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b30d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import hamming_loss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce27339",
   "metadata": {},
   "source": [
    "## 1. Multi-class and Multi-Label Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd90b90",
   "metadata": {},
   "source": [
    "### a) Download the Anuran Calls (MFCCs) Data Set from: https://archive.ics.uci.edu/ml/datasets/Anuran+Calls+%28MFCCs%29. Choose 70% of the data randomly as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d107bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Frogs_MFCCs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35790cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1150709c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_13</th>\n",
       "      <th>MFCCs_14</th>\n",
       "      <th>MFCCs_15</th>\n",
       "      <th>MFCCs_16</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.158646</td>\n",
       "      <td>0.534379</td>\n",
       "      <td>0.276438</td>\n",
       "      <td>-0.113383</td>\n",
       "      <td>0.294784</td>\n",
       "      <td>0.157811</td>\n",
       "      <td>-0.213827</td>\n",
       "      <td>0.052966</td>\n",
       "      <td>0.175000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.217513</td>\n",
       "      <td>0.115549</td>\n",
       "      <td>-0.142948</td>\n",
       "      <td>-0.043739</td>\n",
       "      <td>-0.027222</td>\n",
       "      <td>-0.028655</td>\n",
       "      <td>0.082999</td>\n",
       "      <td>0.146133</td>\n",
       "      <td>0.049442</td>\n",
       "      <td>-0.084164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.157730</td>\n",
       "      <td>0.129206</td>\n",
       "      <td>0.591634</td>\n",
       "      <td>0.275526</td>\n",
       "      <td>-0.006178</td>\n",
       "      <td>-0.153495</td>\n",
       "      <td>0.082747</td>\n",
       "      <td>0.206555</td>\n",
       "      <td>-0.110400</td>\n",
       "      <td>...</td>\n",
       "      <td>0.324661</td>\n",
       "      <td>-0.203326</td>\n",
       "      <td>-0.268547</td>\n",
       "      <td>0.113816</td>\n",
       "      <td>0.179313</td>\n",
       "      <td>-0.037457</td>\n",
       "      <td>-0.141004</td>\n",
       "      <td>-0.094309</td>\n",
       "      <td>0.106879</td>\n",
       "      <td>0.186066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.828310</td>\n",
       "      <td>0.243861</td>\n",
       "      <td>0.135409</td>\n",
       "      <td>0.166489</td>\n",
       "      <td>0.386477</td>\n",
       "      <td>0.435395</td>\n",
       "      <td>0.219620</td>\n",
       "      <td>0.026417</td>\n",
       "      <td>-0.152293</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.275076</td>\n",
       "      <td>-0.034042</td>\n",
       "      <td>0.042109</td>\n",
       "      <td>-0.171347</td>\n",
       "      <td>-0.301549</td>\n",
       "      <td>-0.475986</td>\n",
       "      <td>-0.471597</td>\n",
       "      <td>-0.208141</td>\n",
       "      <td>-0.007926</td>\n",
       "      <td>0.030605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.015939</td>\n",
       "      <td>0.121945</td>\n",
       "      <td>0.479598</td>\n",
       "      <td>0.053737</td>\n",
       "      <td>-0.005948</td>\n",
       "      <td>-0.078343</td>\n",
       "      <td>0.044297</td>\n",
       "      <td>0.289690</td>\n",
       "      <td>0.084880</td>\n",
       "      <td>...</td>\n",
       "      <td>0.199034</td>\n",
       "      <td>-0.174799</td>\n",
       "      <td>-0.165752</td>\n",
       "      <td>0.126657</td>\n",
       "      <td>0.127599</td>\n",
       "      <td>0.045503</td>\n",
       "      <td>0.004640</td>\n",
       "      <td>-0.071200</td>\n",
       "      <td>0.067910</td>\n",
       "      <td>0.152645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.145449</td>\n",
       "      <td>0.215023</td>\n",
       "      <td>0.688683</td>\n",
       "      <td>0.192779</td>\n",
       "      <td>0.067867</td>\n",
       "      <td>-0.044627</td>\n",
       "      <td>0.082023</td>\n",
       "      <td>0.207315</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>...</td>\n",
       "      <td>0.152739</td>\n",
       "      <td>-0.223397</td>\n",
       "      <td>-0.067073</td>\n",
       "      <td>0.299766</td>\n",
       "      <td>0.159250</td>\n",
       "      <td>-0.076507</td>\n",
       "      <td>-0.077418</td>\n",
       "      <td>-0.077509</td>\n",
       "      <td>0.118048</td>\n",
       "      <td>0.254046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.164155</td>\n",
       "      <td>0.240342</td>\n",
       "      <td>0.603025</td>\n",
       "      <td>0.163849</td>\n",
       "      <td>0.006236</td>\n",
       "      <td>-0.101984</td>\n",
       "      <td>0.094291</td>\n",
       "      <td>0.311779</td>\n",
       "      <td>0.033328</td>\n",
       "      <td>...</td>\n",
       "      <td>0.281446</td>\n",
       "      <td>-0.175565</td>\n",
       "      <td>-0.220382</td>\n",
       "      <td>0.123637</td>\n",
       "      <td>0.195625</td>\n",
       "      <td>0.021879</td>\n",
       "      <td>-0.069427</td>\n",
       "      <td>-0.089395</td>\n",
       "      <td>0.067826</td>\n",
       "      <td>0.112058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.408306</td>\n",
       "      <td>0.264014</td>\n",
       "      <td>0.435050</td>\n",
       "      <td>0.171421</td>\n",
       "      <td>0.127738</td>\n",
       "      <td>0.191343</td>\n",
       "      <td>-0.022585</td>\n",
       "      <td>-0.131846</td>\n",
       "      <td>0.047509</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.276959</td>\n",
       "      <td>0.153144</td>\n",
       "      <td>0.202171</td>\n",
       "      <td>-0.176625</td>\n",
       "      <td>-0.234048</td>\n",
       "      <td>-0.022756</td>\n",
       "      <td>-0.055081</td>\n",
       "      <td>-0.095792</td>\n",
       "      <td>0.009612</td>\n",
       "      <td>0.039744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5033</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.492655</td>\n",
       "      <td>0.276040</td>\n",
       "      <td>0.407506</td>\n",
       "      <td>0.192651</td>\n",
       "      <td>0.048210</td>\n",
       "      <td>-0.055457</td>\n",
       "      <td>0.008024</td>\n",
       "      <td>0.187479</td>\n",
       "      <td>0.138029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.163116</td>\n",
       "      <td>0.157449</td>\n",
       "      <td>-0.101399</td>\n",
       "      <td>-0.096676</td>\n",
       "      <td>0.011191</td>\n",
       "      <td>0.042344</td>\n",
       "      <td>0.008098</td>\n",
       "      <td>-0.037977</td>\n",
       "      <td>-0.103140</td>\n",
       "      <td>-0.022722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.017325</td>\n",
       "      <td>0.164911</td>\n",
       "      <td>0.625717</td>\n",
       "      <td>0.289707</td>\n",
       "      <td>0.109264</td>\n",
       "      <td>-0.113049</td>\n",
       "      <td>-0.052196</td>\n",
       "      <td>0.215732</td>\n",
       "      <td>0.049555</td>\n",
       "      <td>...</td>\n",
       "      <td>0.200085</td>\n",
       "      <td>-0.326034</td>\n",
       "      <td>-0.185656</td>\n",
       "      <td>0.327710</td>\n",
       "      <td>0.255466</td>\n",
       "      <td>-0.103170</td>\n",
       "      <td>-0.182513</td>\n",
       "      <td>-0.040778</td>\n",
       "      <td>0.222275</td>\n",
       "      <td>0.213486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5035</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.124809</td>\n",
       "      <td>0.293327</td>\n",
       "      <td>0.351964</td>\n",
       "      <td>0.189044</td>\n",
       "      <td>0.176902</td>\n",
       "      <td>0.096410</td>\n",
       "      <td>-0.132082</td>\n",
       "      <td>-0.094573</td>\n",
       "      <td>0.085046</td>\n",
       "      <td>...</td>\n",
       "      <td>0.102510</td>\n",
       "      <td>-0.056236</td>\n",
       "      <td>-0.146310</td>\n",
       "      <td>0.014912</td>\n",
       "      <td>0.123551</td>\n",
       "      <td>0.052387</td>\n",
       "      <td>0.005640</td>\n",
       "      <td>-0.031456</td>\n",
       "      <td>-0.074508</td>\n",
       "      <td>0.026667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5036 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0          1.0  0.158646  0.534379  0.276438 -0.113383  0.294784  0.157811   \n",
       "1          1.0  0.157730  0.129206  0.591634  0.275526 -0.006178 -0.153495   \n",
       "2          1.0  0.828310  0.243861  0.135409  0.166489  0.386477  0.435395   \n",
       "3          1.0  0.015939  0.121945  0.479598  0.053737 -0.005948 -0.078343   \n",
       "4          1.0  0.145449  0.215023  0.688683  0.192779  0.067867 -0.044627   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5031       1.0  0.164155  0.240342  0.603025  0.163849  0.006236 -0.101984   \n",
       "5032       1.0  0.408306  0.264014  0.435050  0.171421  0.127738  0.191343   \n",
       "5033       1.0  0.492655  0.276040  0.407506  0.192651  0.048210 -0.055457   \n",
       "5034       1.0  0.017325  0.164911  0.625717  0.289707  0.109264 -0.113049   \n",
       "5035       1.0  0.124809  0.293327  0.351964  0.189044  0.176902  0.096410   \n",
       "\n",
       "      MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_13  MFCCs_14  MFCCs_15  \\\n",
       "0    -0.213827  0.052966  0.175000  ...  0.217513  0.115549 -0.142948   \n",
       "1     0.082747  0.206555 -0.110400  ...  0.324661 -0.203326 -0.268547   \n",
       "2     0.219620  0.026417 -0.152293  ... -0.275076 -0.034042  0.042109   \n",
       "3     0.044297  0.289690  0.084880  ...  0.199034 -0.174799 -0.165752   \n",
       "4     0.082023  0.207315  0.004216  ...  0.152739 -0.223397 -0.067073   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5031  0.094291  0.311779  0.033328  ...  0.281446 -0.175565 -0.220382   \n",
       "5032 -0.022585 -0.131846  0.047509  ... -0.276959  0.153144  0.202171   \n",
       "5033  0.008024  0.187479  0.138029  ...  0.163116  0.157449 -0.101399   \n",
       "5034 -0.052196  0.215732  0.049555  ...  0.200085 -0.326034 -0.185656   \n",
       "5035 -0.132082 -0.094573  0.085046  ...  0.102510 -0.056236 -0.146310   \n",
       "\n",
       "      MFCCs_16  MFCCs_17  MFCCs_18  MFCCs_19  MFCCs_20  MFCCs_21  MFCCs_22  \n",
       "0    -0.043739 -0.027222 -0.028655  0.082999  0.146133  0.049442 -0.084164  \n",
       "1     0.113816  0.179313 -0.037457 -0.141004 -0.094309  0.106879  0.186066  \n",
       "2    -0.171347 -0.301549 -0.475986 -0.471597 -0.208141 -0.007926  0.030605  \n",
       "3     0.126657  0.127599  0.045503  0.004640 -0.071200  0.067910  0.152645  \n",
       "4     0.299766  0.159250 -0.076507 -0.077418 -0.077509  0.118048  0.254046  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5031  0.123637  0.195625  0.021879 -0.069427 -0.089395  0.067826  0.112058  \n",
       "5032 -0.176625 -0.234048 -0.022756 -0.055081 -0.095792  0.009612  0.039744  \n",
       "5033 -0.096676  0.011191  0.042344  0.008098 -0.037977 -0.103140 -0.022722  \n",
       "5034  0.327710  0.255466 -0.103170 -0.182513 -0.040778  0.222275  0.213486  \n",
       "5035  0.014912  0.123551  0.052387  0.005640 -0.031456 -0.074508  0.026667  \n",
       "\n",
       "[5036 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.reset_index(drop=True, inplace = True)\n",
    "train_x = train.drop(columns = ['Family','Genus','Species','RecordID'])\n",
    "train_y_family = train['Family']\n",
    "train_y_genus = train['Genus']\n",
    "train_y_species = train['Species']\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92e14af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reset_index(drop=True, inplace = True)\n",
    "test_x = test.drop(columns = ['Family','Genus','Species','RecordID'])\n",
    "#test_y_family = test[['Family']]\n",
    "#test_y_genus = test['Genus'].tolist()\n",
    "#test_y_species = test['Species'].tolist()\n",
    "#type(test_y_family)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb7cc44",
   "metadata": {},
   "source": [
    "### b) Each instance has three labels: Families, Genus, and Species. Each of the labels has multiple classes. We wish to solve a multi-class and multi-label problem. One of the most important approaches to multi-label classification is to train a classifier for each label (binary relevance). We first try this approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b484410",
   "metadata": {},
   "source": [
    "#### i) Research exact match and hamming score/ loss methods for evaluating multi\u0002label classification and use them in evaluating the classifiers in this problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d19c9",
   "metadata": {},
   "source": [
    "Exact match\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "\n",
    "Hamming loss is the fraction of wrong labels to the total number of labels. In multi-class classification, hamming loss is calculated as the hamming distance between y_true and y_pred. \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hamming_loss.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc72b4d0",
   "metadata": {},
   "source": [
    "#### ii) Train a SVM for each of the labels, using Gaussian kernels and one versus all classifiers. Determine the weight of the SVM penalty and the width of the Gaussian Kernel using 10 fold cross validation. You are welcome to try to solve the problem with both standardized 2 and raw attributes and report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081e4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18c44d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_gaussian (column_name):\n",
    "    train_y = train[column_name]\n",
    "    test_y = test[[column_name]]\n",
    "    clf = svm.SVC(kernel = 'rbf')\n",
    "    C_list = []\n",
    "    k = range(-3,6)#-3,6\n",
    "    for i in k:\n",
    "        C_list.append(10**(i))\n",
    "    params = {'C':C_list,'gamma': np.linspace(0.1,2,20)}#(0.1,2,20)\n",
    "    grid = GridSearchCV(clf, param_grid = params, cv = 10)\n",
    "    grid.fit(train_x, train_y)\n",
    "    pred_y = grid.predict(test_x)\n",
    "    optimal_estimator = grid.best_estimator_\n",
    "    optimal_params = grid.best_params_\n",
    "    hamming_los = hamming_loss(test_y,pred_y)\n",
    "    #print ('hamming_loss:', hamming_los)\n",
    "    correct = 0\n",
    "    test_y_ = test[column_name].tolist()\n",
    "    for i in range(len(test_y_)):\n",
    "        if test_y_[i] == pred_y[i]:\n",
    "            correct+=1\n",
    "    exact_match = correct/len(test_y_)\n",
    "    #print ('exact_match:', exact_match)\n",
    "    return ('optimal_params:',optimal_params,'hamming_loss:', hamming_los,'exact_match:', exact_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "182bcd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('optimal_params:',\n",
       " {'C': 100, 'gamma': 1.5999999999999999},\n",
       " 'hamming_loss:',\n",
       " 0.006021306160259379,\n",
       " 'exact_match:',\n",
       " 0.9939786938397406)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_gaussian('Family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae9913a",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_gaussian('Genus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a280928",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "svc_gaussian('Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ad128e",
   "metadata": {},
   "source": [
    "#### iii) Repeat 1(b)ii with L1-penalized SVMs. Remember to standardize4 the attributes. Determine the weight of the SVM penalty using 10 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009afd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler().fit(train_x)\n",
    "#mean = scaler.mean_\n",
    "#train_x = scaler.transform(train_x)\n",
    "#test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "932cf5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_L1_penalized (column_name):\n",
    "    train_y = train[column_name]\n",
    "    test_y = test[[column_name]]\n",
    "    clf = svm.LinearSVC(penalty = 'l1', dual=False)\n",
    "    C_list = []\n",
    "    k = range(-3,6)#-3,6\n",
    "    for i in k:\n",
    "        C_list.append(10**(i))\n",
    "    params = {'C':C_list}\n",
    "    grid = GridSearchCV(svm.LinearSVC(penalty = 'l1', dual=False), param_grid = params, cv = 10)\n",
    "    grid.fit(train_x, train_y)\n",
    "    pred_y = grid.predict(test_x)\n",
    "    optimal_estimator = grid.best_estimator_\n",
    "    optimal_params = grid.best_params_\n",
    "    hamming_los = hamming_loss(test_y,pred_y)\n",
    "    #print ('hamming_loss:', hamming_los)\n",
    "    correct = 0\n",
    "    test_y_ = test[column_name].tolist()\n",
    "    for i in range(len(test_y_)):\n",
    "        if test_y_[i] == pred_y[i]:\n",
    "            correct+=1\n",
    "    exact_match = correct/len(test_y_)\n",
    "    #print ('exact_match:', exact_match)\n",
    "    return ('optimal_params:',optimal_params,'hamming_loss:', hamming_los,'exact_match:', exact_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e360bb6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "svc_L1_penalized('Family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9e231d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_L1_penalized('Genus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52656fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_L1_penalized('Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fdf9ebf",
   "metadata": {},
   "source": [
    "#### iv) Repeat 1(b)iii by using SMOTE or any other method you know to remedy class imbalance. Report your conclusions about the classifiers you trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9502dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17889409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_L1_SMOTE (column_name):\n",
    "    smt = SMOTE(random_state=42)\n",
    "    train_x_smote, train_y_smote = smt.fit_resample(train_x,train[column_name])\n",
    "    test_y = test[[column_name]]\n",
    "    \n",
    "    clf = svm.LinearSVC(penalty = 'l1', dual=False)\n",
    "    C_list = []\n",
    "    k = range(-3,6)#-3,6\n",
    "    for i in k:\n",
    "        C_list.append(10**(i))\n",
    "    params = {'C':C_list}\n",
    "    grid = GridSearchCV(svm.LinearSVC(penalty = 'l1', dual=False), param_grid = params, cv = 10)\n",
    "    grid.fit(train_x_smote, train_y_smote)\n",
    "    pred_y = grid.predict(test_x)\n",
    "    optimal_estimator = grid.best_estimator_\n",
    "    optimal_params = grid.best_params_\n",
    "    hamming_los = hamming_loss(test_y,pred_y)\n",
    "    #print ('hamming_loss:', hamming_los)\n",
    "    correct = 0\n",
    "    test_y_ = test[column_name].tolist()\n",
    "    for i in range(len(test_y_)):\n",
    "        if test_y_[i] == pred_y[i]:\n",
    "            correct+=1\n",
    "    exact_match = correct/len(test_y_)\n",
    "    #print ('exact_match:', exact_match)\n",
    "    return ('optimal_params:',optimal_params,'hamming_loss:', hamming_los,'exact_match:', exact_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c2ef23",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_L1_SMOTE('Family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605efcb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_L1_SMOTE('Genus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f7da87",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_L1_SMOTE('Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ff8a68",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5802f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a4dc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c11a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
