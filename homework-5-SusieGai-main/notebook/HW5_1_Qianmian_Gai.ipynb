{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74b30d46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import hamming_loss\n",
    "from sklearn import preprocessing\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import hamming_loss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce27339",
   "metadata": {},
   "source": [
    "## 1. Multi-class and Multi-Label Classification Using Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd90b90",
   "metadata": {},
   "source": [
    "### a) Download the Anuran Calls (MFCCs) Data Set from: https://archive.ics.uci.edu/ml/datasets/Anuran+Calls+%28MFCCs%29. Choose 70% of the data randomly as the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d107bebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/Frogs_MFCCs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "35790cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1150709c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MFCCs_ 1</th>\n",
       "      <th>MFCCs_ 2</th>\n",
       "      <th>MFCCs_ 3</th>\n",
       "      <th>MFCCs_ 4</th>\n",
       "      <th>MFCCs_ 5</th>\n",
       "      <th>MFCCs_ 6</th>\n",
       "      <th>MFCCs_ 7</th>\n",
       "      <th>MFCCs_ 8</th>\n",
       "      <th>MFCCs_ 9</th>\n",
       "      <th>MFCCs_10</th>\n",
       "      <th>...</th>\n",
       "      <th>MFCCs_13</th>\n",
       "      <th>MFCCs_14</th>\n",
       "      <th>MFCCs_15</th>\n",
       "      <th>MFCCs_16</th>\n",
       "      <th>MFCCs_17</th>\n",
       "      <th>MFCCs_18</th>\n",
       "      <th>MFCCs_19</th>\n",
       "      <th>MFCCs_20</th>\n",
       "      <th>MFCCs_21</th>\n",
       "      <th>MFCCs_22</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.678890</td>\n",
       "      <td>0.627786</td>\n",
       "      <td>0.417648</td>\n",
       "      <td>0.006501</td>\n",
       "      <td>0.047394</td>\n",
       "      <td>-0.013962</td>\n",
       "      <td>0.171826</td>\n",
       "      <td>0.164646</td>\n",
       "      <td>-0.348734</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147417</td>\n",
       "      <td>-0.272056</td>\n",
       "      <td>0.250713</td>\n",
       "      <td>0.111075</td>\n",
       "      <td>-0.126669</td>\n",
       "      <td>-0.082302</td>\n",
       "      <td>0.013090</td>\n",
       "      <td>0.145827</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>-0.228808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.592463</td>\n",
       "      <td>0.594306</td>\n",
       "      <td>0.614234</td>\n",
       "      <td>-0.062790</td>\n",
       "      <td>-0.002779</td>\n",
       "      <td>0.406548</td>\n",
       "      <td>0.042052</td>\n",
       "      <td>-0.290214</td>\n",
       "      <td>0.121748</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.097734</td>\n",
       "      <td>0.186441</td>\n",
       "      <td>0.035633</td>\n",
       "      <td>-0.163825</td>\n",
       "      <td>0.062933</td>\n",
       "      <td>0.034034</td>\n",
       "      <td>-0.090153</td>\n",
       "      <td>-0.029221</td>\n",
       "      <td>0.156980</td>\n",
       "      <td>0.051274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.668390</td>\n",
       "      <td>0.730198</td>\n",
       "      <td>0.580968</td>\n",
       "      <td>-0.162741</td>\n",
       "      <td>-0.081930</td>\n",
       "      <td>0.432132</td>\n",
       "      <td>0.032331</td>\n",
       "      <td>-0.255920</td>\n",
       "      <td>0.185829</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051825</td>\n",
       "      <td>0.216703</td>\n",
       "      <td>0.085594</td>\n",
       "      <td>-0.077685</td>\n",
       "      <td>0.044806</td>\n",
       "      <td>0.058034</td>\n",
       "      <td>-0.117957</td>\n",
       "      <td>-0.023452</td>\n",
       "      <td>0.061707</td>\n",
       "      <td>-0.061029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.499485</td>\n",
       "      <td>0.871131</td>\n",
       "      <td>0.130839</td>\n",
       "      <td>-0.057632</td>\n",
       "      <td>0.228049</td>\n",
       "      <td>0.113412</td>\n",
       "      <td>0.030765</td>\n",
       "      <td>-0.062252</td>\n",
       "      <td>0.114443</td>\n",
       "      <td>...</td>\n",
       "      <td>0.048553</td>\n",
       "      <td>0.036052</td>\n",
       "      <td>0.005987</td>\n",
       "      <td>-0.015289</td>\n",
       "      <td>0.014579</td>\n",
       "      <td>0.060369</td>\n",
       "      <td>-0.038024</td>\n",
       "      <td>0.027430</td>\n",
       "      <td>0.060819</td>\n",
       "      <td>-0.017502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.528867</td>\n",
       "      <td>0.177182</td>\n",
       "      <td>0.480349</td>\n",
       "      <td>0.235936</td>\n",
       "      <td>0.058119</td>\n",
       "      <td>-0.113591</td>\n",
       "      <td>0.109672</td>\n",
       "      <td>0.269437</td>\n",
       "      <td>0.018172</td>\n",
       "      <td>...</td>\n",
       "      <td>0.304922</td>\n",
       "      <td>0.031393</td>\n",
       "      <td>-0.283915</td>\n",
       "      <td>-0.133012</td>\n",
       "      <td>0.144055</td>\n",
       "      <td>0.104321</td>\n",
       "      <td>-0.034758</td>\n",
       "      <td>-0.149859</td>\n",
       "      <td>0.041324</td>\n",
       "      <td>0.173693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5031</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.158996</td>\n",
       "      <td>0.051412</td>\n",
       "      <td>0.444340</td>\n",
       "      <td>0.187838</td>\n",
       "      <td>-0.044646</td>\n",
       "      <td>-0.190111</td>\n",
       "      <td>0.022224</td>\n",
       "      <td>0.237797</td>\n",
       "      <td>0.098919</td>\n",
       "      <td>...</td>\n",
       "      <td>0.262036</td>\n",
       "      <td>-0.139650</td>\n",
       "      <td>-0.212224</td>\n",
       "      <td>0.075515</td>\n",
       "      <td>0.140946</td>\n",
       "      <td>-0.070769</td>\n",
       "      <td>-0.157801</td>\n",
       "      <td>-0.097470</td>\n",
       "      <td>0.141041</td>\n",
       "      <td>0.213570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5032</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.411093</td>\n",
       "      <td>0.361243</td>\n",
       "      <td>0.599813</td>\n",
       "      <td>0.228860</td>\n",
       "      <td>0.046402</td>\n",
       "      <td>-0.122935</td>\n",
       "      <td>0.048862</td>\n",
       "      <td>0.297221</td>\n",
       "      <td>0.062370</td>\n",
       "      <td>...</td>\n",
       "      <td>0.392131</td>\n",
       "      <td>-0.130987</td>\n",
       "      <td>-0.300936</td>\n",
       "      <td>0.139467</td>\n",
       "      <td>0.261435</td>\n",
       "      <td>0.057003</td>\n",
       "      <td>-0.095145</td>\n",
       "      <td>-0.161296</td>\n",
       "      <td>0.025276</td>\n",
       "      <td>0.146362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5033</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.143910</td>\n",
       "      <td>0.215908</td>\n",
       "      <td>0.614139</td>\n",
       "      <td>0.245914</td>\n",
       "      <td>0.051628</td>\n",
       "      <td>-0.120428</td>\n",
       "      <td>0.065981</td>\n",
       "      <td>0.240651</td>\n",
       "      <td>0.011891</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285553</td>\n",
       "      <td>-0.245838</td>\n",
       "      <td>-0.171299</td>\n",
       "      <td>0.247508</td>\n",
       "      <td>0.183207</td>\n",
       "      <td>-0.119715</td>\n",
       "      <td>-0.184234</td>\n",
       "      <td>-0.067429</td>\n",
       "      <td>0.161457</td>\n",
       "      <td>0.145647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5034</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.161899</td>\n",
       "      <td>0.055097</td>\n",
       "      <td>0.532344</td>\n",
       "      <td>0.153751</td>\n",
       "      <td>0.038912</td>\n",
       "      <td>-0.199959</td>\n",
       "      <td>-0.062128</td>\n",
       "      <td>0.231903</td>\n",
       "      <td>0.062480</td>\n",
       "      <td>...</td>\n",
       "      <td>0.394535</td>\n",
       "      <td>-0.090245</td>\n",
       "      <td>-0.304619</td>\n",
       "      <td>0.038661</td>\n",
       "      <td>0.233265</td>\n",
       "      <td>0.057278</td>\n",
       "      <td>-0.118224</td>\n",
       "      <td>-0.200734</td>\n",
       "      <td>0.015283</td>\n",
       "      <td>0.213167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5035</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.220825</td>\n",
       "      <td>0.255842</td>\n",
       "      <td>0.432942</td>\n",
       "      <td>0.089357</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>-0.068168</td>\n",
       "      <td>0.102503</td>\n",
       "      <td>0.334812</td>\n",
       "      <td>0.001575</td>\n",
       "      <td>...</td>\n",
       "      <td>0.302684</td>\n",
       "      <td>-0.217519</td>\n",
       "      <td>-0.131866</td>\n",
       "      <td>0.247819</td>\n",
       "      <td>0.137322</td>\n",
       "      <td>-0.052014</td>\n",
       "      <td>-0.123376</td>\n",
       "      <td>-0.110684</td>\n",
       "      <td>0.099874</td>\n",
       "      <td>0.137811</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5036 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      MFCCs_ 1  MFCCs_ 2  MFCCs_ 3  MFCCs_ 4  MFCCs_ 5  MFCCs_ 6  MFCCs_ 7  \\\n",
       "0          1.0  0.678890  0.627786  0.417648  0.006501  0.047394 -0.013962   \n",
       "1          1.0  0.592463  0.594306  0.614234 -0.062790 -0.002779  0.406548   \n",
       "2          1.0  0.668390  0.730198  0.580968 -0.162741 -0.081930  0.432132   \n",
       "3          1.0  0.499485  0.871131  0.130839 -0.057632  0.228049  0.113412   \n",
       "4          1.0  0.528867  0.177182  0.480349  0.235936  0.058119 -0.113591   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "5031       1.0  0.158996  0.051412  0.444340  0.187838 -0.044646 -0.190111   \n",
       "5032       1.0  0.411093  0.361243  0.599813  0.228860  0.046402 -0.122935   \n",
       "5033       1.0  0.143910  0.215908  0.614139  0.245914  0.051628 -0.120428   \n",
       "5034       1.0  0.161899  0.055097  0.532344  0.153751  0.038912 -0.199959   \n",
       "5035       1.0  0.220825  0.255842  0.432942  0.089357  0.002863 -0.068168   \n",
       "\n",
       "      MFCCs_ 8  MFCCs_ 9  MFCCs_10  ...  MFCCs_13  MFCCs_14  MFCCs_15  \\\n",
       "0     0.171826  0.164646 -0.348734  ... -0.147417 -0.272056  0.250713   \n",
       "1     0.042052 -0.290214  0.121748  ... -0.097734  0.186441  0.035633   \n",
       "2     0.032331 -0.255920  0.185829  ... -0.051825  0.216703  0.085594   \n",
       "3     0.030765 -0.062252  0.114443  ...  0.048553  0.036052  0.005987   \n",
       "4     0.109672  0.269437  0.018172  ...  0.304922  0.031393 -0.283915   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "5031  0.022224  0.237797  0.098919  ...  0.262036 -0.139650 -0.212224   \n",
       "5032  0.048862  0.297221  0.062370  ...  0.392131 -0.130987 -0.300936   \n",
       "5033  0.065981  0.240651  0.011891  ...  0.285553 -0.245838 -0.171299   \n",
       "5034 -0.062128  0.231903  0.062480  ...  0.394535 -0.090245 -0.304619   \n",
       "5035  0.102503  0.334812  0.001575  ...  0.302684 -0.217519 -0.131866   \n",
       "\n",
       "      MFCCs_16  MFCCs_17  MFCCs_18  MFCCs_19  MFCCs_20  MFCCs_21  MFCCs_22  \n",
       "0     0.111075 -0.126669 -0.082302  0.013090  0.145827  0.013956 -0.228808  \n",
       "1    -0.163825  0.062933  0.034034 -0.090153 -0.029221  0.156980  0.051274  \n",
       "2    -0.077685  0.044806  0.058034 -0.117957 -0.023452  0.061707 -0.061029  \n",
       "3    -0.015289  0.014579  0.060369 -0.038024  0.027430  0.060819 -0.017502  \n",
       "4    -0.133012  0.144055  0.104321 -0.034758 -0.149859  0.041324  0.173693  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "5031  0.075515  0.140946 -0.070769 -0.157801 -0.097470  0.141041  0.213570  \n",
       "5032  0.139467  0.261435  0.057003 -0.095145 -0.161296  0.025276  0.146362  \n",
       "5033  0.247508  0.183207 -0.119715 -0.184234 -0.067429  0.161457  0.145647  \n",
       "5034  0.038661  0.233265  0.057278 -0.118224 -0.200734  0.015283  0.213167  \n",
       "5035  0.247819  0.137322 -0.052014 -0.123376 -0.110684  0.099874  0.137811  \n",
       "\n",
       "[5036 rows x 22 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.reset_index(drop=True, inplace = True)\n",
    "train_x = train.drop(columns = ['Family','Genus','Species','RecordID'])\n",
    "train_y_family = train['Family']\n",
    "train_y_genus = train['Genus']\n",
    "train_y_species = train['Species']\n",
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92e14af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reset_index(drop=True, inplace = True)\n",
    "test_x = test.drop(columns = ['Family','Genus','Species','RecordID'])\n",
    "#test_y_family = test[['Family']]\n",
    "#test_y_genus = test['Genus'].tolist()\n",
    "#test_y_species = test['Species'].tolist()\n",
    "#type(test_y_family)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb7cc44",
   "metadata": {},
   "source": [
    "### b) Each instance has three labels: Families, Genus, and Species. Each of the labels has multiple classes. We wish to solve a multi-class and multi-label problem. One of the most important approaches to multi-label classification is to train a classifier for each label (binary relevance). We first try this approach:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b484410",
   "metadata": {},
   "source": [
    "#### i) Research exact match and hamming score/ loss methods for evaluating multi\u0002label classification and use them in evaluating the classifiers in this problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995d19c9",
   "metadata": {},
   "source": [
    "Exact match\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html\n",
    "\n",
    "Hamming loss is the fraction of wrong labels to the total number of labels. In multi-class classification, hamming loss is calculated as the hamming distance between y_true and y_pred. \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.metrics.hamming_loss.html\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc72b4d0",
   "metadata": {},
   "source": [
    "#### ii) Train a SVM for each of the labels, using Gaussian kernels and one versus all classifiers. Determine the weight of the SVM penalty and the width of the Gaussian Kernel using 10 fold cross validation. You are welcome to try to solve the problem with both standardized 2 and raw attributes and report the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "081e4536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import hamming_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18c44d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_gaussian (column_name):\n",
    "    train_y = train[column_name]\n",
    "    test_y = test[[column_name]]\n",
    "    clf = svm.SVC(kernel = 'rbf')\n",
    "    C_list = []\n",
    "    k = range(-3,6)#-3,6\n",
    "    for i in k:\n",
    "        C_list.append(10**(i))\n",
    "    params = {'C':C_list,'gamma': np.linspace(0.1,2,20)}#(0.1,2,20)\n",
    "    grid = GridSearchCV(clf, param_grid = params, cv = 10)\n",
    "    grid.fit(train_x, train_y)\n",
    "    pred_y = grid.predict(test_x)\n",
    "    optimal_estimator = grid.best_estimator_\n",
    "    optimal_params = grid.best_params_\n",
    "    hamming_los = hamming_loss(test_y,pred_y)\n",
    "    #print ('hamming_loss:', hamming_los)\n",
    "    correct = 0\n",
    "    test_y_ = test[column_name].tolist()\n",
    "    for i in range(len(test_y_)):\n",
    "        if test_y_[i] == pred_y[i]:\n",
    "            correct+=1\n",
    "    exact_match = correct/len(test_y_)\n",
    "    #print ('exact_match:', exact_match)\n",
    "    return ('optimal_params:',optimal_params,'hamming_loss:', hamming_los,'exact_match:', exact_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "182bcd69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('optimal_params:',\n",
       " {'C': 10, 'gamma': 1.9},\n",
       " 'hamming_loss:',\n",
       " 0.008800370541917554,\n",
       " 'exact_match:',\n",
       " 0.9911996294580825)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_gaussian('Family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bae9913a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('optimal_params:',\n",
       " {'C': 10, 'gamma': 1.3},\n",
       " 'hamming_loss:',\n",
       " 0.010189902732746642,\n",
       " 'exact_match:',\n",
       " 0.9898100972672533)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_gaussian('Genus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a280928",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('optimal_params:',\n",
       " {'C': 10, 'gamma': 1.0999999999999999},\n",
       " 'hamming_loss:',\n",
       " 0.010189902732746642,\n",
       " 'exact_match:',\n",
       " 0.9898100972672533)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_gaussian('Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ad128e",
   "metadata": {},
   "source": [
    "#### iii) Repeat 1(b)ii with L1-penalized SVMs. Remember to standardize4 the attributes. Determine the weight of the SVM penalty using 10 fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "009afd7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.preprocessing import StandardScaler\n",
    "#scaler = StandardScaler().fit(train_x)\n",
    "#mean = scaler.mean_\n",
    "#train_x = scaler.transform(train_x)\n",
    "#test_x = scaler.transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "932cf5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_L1_penalized (column_name):\n",
    "    train_y = train[column_name]\n",
    "    test_y = test[[column_name]]\n",
    "    clf = svm.LinearSVC(penalty = 'l1', dual=False)\n",
    "    C_list = []\n",
    "    k = range(-3,6)#-3,6\n",
    "    for i in k:\n",
    "        C_list.append(10**(i))\n",
    "    params = {'C':C_list}\n",
    "    grid = GridSearchCV(svm.LinearSVC(penalty = 'l1', dual=False), param_grid = params, cv = 10)\n",
    "    grid.fit(train_x, train_y)\n",
    "    pred_y = grid.predict(test_x)\n",
    "    optimal_estimator = grid.best_estimator_\n",
    "    optimal_params = grid.best_params_\n",
    "    hamming_los = hamming_loss(test_y,pred_y)\n",
    "    #print ('hamming_loss:', hamming_los)\n",
    "    correct = 0\n",
    "    test_y_ = test[column_name].tolist()\n",
    "    for i in range(len(test_y_)):\n",
    "        if test_y_[i] == pred_y[i]:\n",
    "            correct+=1\n",
    "    exact_match = correct/len(test_y_)\n",
    "    #print ('exact_match:', exact_match)\n",
    "    return ('optimal_params:',optimal_params,'hamming_loss:', hamming_los,'exact_match:', exact_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e360bb6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('optimal_params:',\n",
       " {'C': 10},\n",
       " 'hamming_loss:',\n",
       " 0.06484483557202408,\n",
       " 'exact_match:',\n",
       " 0.9351551644279759)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_L1_penalized('Family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb9e231d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('optimal_params:',\n",
       " {'C': 100000},\n",
       " 'hamming_loss:',\n",
       " 0.048170449282075034,\n",
       " 'exact_match:',\n",
       " 0.951829550717925)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_L1_penalized('Genus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "52656fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('optimal_params:',\n",
       " {'C': 100},\n",
       " 'hamming_loss:',\n",
       " 0.03844372394627142,\n",
       " 'exact_match:',\n",
       " 0.9615562760537286)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_L1_penalized('Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd0a35b",
   "metadata": {},
   "source": [
    "#### iv) Repeat 1(b)iii by using SMOTE or any other method you know to remedy class imbalance. Report your conclusions about the classifiers you trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9502dc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "17889409",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svc_L1_SMOTE (column_name):\n",
    "    smt = SMOTE(random_state=42)\n",
    "    train_x_smote, train_y_smote = smt.fit_resample(train_x,train[column_name])\n",
    "    test_y = test[[column_name]]\n",
    "    \n",
    "    clf = svm.LinearSVC(penalty = 'l1', dual=False)\n",
    "    C_list = []\n",
    "    k = range(-3,6)#-3,6\n",
    "    for i in k:\n",
    "        C_list.append(10**(i))\n",
    "    params = {'C':C_list}\n",
    "    grid = GridSearchCV(svm.LinearSVC(penalty = 'l1', dual=False), param_grid = params, cv = 10)\n",
    "    grid.fit(train_x_smote, train_y_smote)\n",
    "    pred_y = grid.predict(test_x)\n",
    "    optimal_estimator = grid.best_estimator_\n",
    "    optimal_params = grid.best_params_\n",
    "    hamming_los = hamming_loss(test_y,pred_y)\n",
    "    #print ('hamming_loss:', hamming_los)\n",
    "    correct = 0\n",
    "    test_y_ = test[column_name].tolist()\n",
    "    for i in range(len(test_y_)):\n",
    "        if test_y_[i] == pred_y[i]:\n",
    "            correct+=1\n",
    "    exact_match = correct/len(test_y_)\n",
    "    #print ('exact_match:', exact_match)\n",
    "    return ('optimal_params:',optimal_params,'hamming_loss:', hamming_los,'exact_match:', exact_match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "23c2ef23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('optimal_params:',\n",
       " {'C': 10000},\n",
       " 'hamming_loss:',\n",
       " 0.0745715609078277,\n",
       " 'exact_match:',\n",
       " 0.9254284390921723)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_L1_SMOTE('Family')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "605efcb6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('optimal_params:',\n",
       " {'C': 100000},\n",
       " 'hamming_loss:',\n",
       " 0.0810560444650301,\n",
       " 'exact_match:',\n",
       " 0.9189439555349699)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_L1_SMOTE('Genus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f1f7da87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('optimal_params:',\n",
       " {'C': 1000},\n",
       " 'hamming_loss:',\n",
       " 0.04353867531264474,\n",
       " 'exact_match:',\n",
       " 0.9564613246873552)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_L1_SMOTE('Species')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d280fc44",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5802f84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13a4dc1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c11a49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
